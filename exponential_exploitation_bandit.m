% Code used for all plots ? it seems so...

clear;
close all;
home;

% Metadata
K = 10;    % Number of arms
T = 1e4;   % Number of iterations % 20 000 per night, under 1e5 MC points. N=1000,M=1000 ~ 20sec.
M = 70;   %1000 Number of MC samples
Nexp = 1; % Number of experiments to compute a variance estimator
sigma = .1;  % Standard deviation of noise
lambda = 1; % Prior standard deviation of mean rewards
L = 100;    % length of the input for power iterations
eps = 1e-15; % regulations term for p
tolerance = 1e-7;   % treshold to consider a frequency in the Hinf-norm est.
m_re_post = zeros(K,1);
m_im_post = m_re_post;
Ghat = 0;
J = sqrt(-1); 


% Filter properties
% Filter 1: One maximum.
r = 0.95;
w0 = 75/100*pi;
a = [1 -2*r*cos(w0) r^2];
b = 1-r;
% Filter 2: Several maxima.
load('Num.mat');        % Filter coefficients (via fdatool)
a = [1 zeros(1,length(Num)-1)];
b = Num;
% Filter gains
G = freqz(b,a,K+1);
G = G(2:K+1);
absG = abs(G);
Nplot = 1000;
Gplot = abs(freqz(b,a,Nplot));

% True mean reward distribution
mu_re = real(G);
mu_im = imag(G);
[maxmu, index_maxmu] = max(abs(G));
beta = maxmu;

sR_ucbv = zeros(T,1);
sR_ts = sR_ucbv;
sR_wts = sR_ucbv;

for i = 1:Nexp
    p   = ones(K,1)/K;    % Initial weights
    sp  = zeros(K,1);     % Sum of previous weights
    spw_re = zeros(K,1);  % Sum of previous weighted rewards
    spw_im = zeros(K,1);  % Sum of previous weighted rewards

    p_ts   = ones(K,1)/K;    % Initial weights
    sp_ts  = zeros(K,1);     % Sum of previous weights
    spw_re_ts = zeros(K,1);  % Sum of previous weighted rewards
    spw_im_ts = zeros(K,1);  % Sum of previous weighted rewards
    spw_abs = zeros(K,1);    % Sum of previous w. quadratic rewards

    R_ucbv = zeros(T,1);
    R_ts = R_ucbv;
    R_wts = R_ucbv;
    svhat = 0;
    svhat_ts = 0;
    svhat_wts = 0;

    u = zeros(L,1);
    ind = 1;
    ind_ts = 1;
    
    % Game
    tic
    for t = 1:T
        
        % UCB-V
            % Update posterior for each arm
            m_re_post = lambda^2*spw_re ./ (sigma^2 + lambda^2*sp); % Re( post_mean )
            m_im_post = lambda^2*spw_im ./ (sigma^2 + lambda^2*sp); % Im( post_mean )

            % Reward generation
            X_re = mu_re + randn*sigma./sqrt(2*p(ind));
            X_im = mu_im + randn*sigma./sqrt(2*p(ind));

            % Update statistics
            sp  = sp + p;
            spw_re = spw_re + p.*X_re;
            spw_im = spw_im + p.*X_im;
            for k = 1:K
                svhat = svhat + (sqrt(2*p(k))*(X_re(k) - m_re_post(k)))^2;
                svhat = svhat + (sqrt(2*p(k))*(X_im(k) - m_im_post(k)))^2;
            end
            vhat = svhat/(2*t);

            % Expected Cumulative Regret computation
            R_ucbv(t) = R_ucbv(max(t-1,1)) + max(0,maxmu^2 - p'*(abs(G).^2));

            % Udapte p    
            b = m_re_post.^2 + m_im_post.^2 + sqrt(.5*sigma^2*log(t+1)./sp);
            [~,ind] = max(b);
            p = zeros(K,1);
            p(ind) = 1;
        
        % TS
            m_re_post_ts = lambda^2*spw_re_ts ./ (sigma^2 + lambda^2*sp_ts); % Re( post_mean )
            m_im_post_ts = lambda^2*spw_im_ts ./ (sigma^2 + lambda^2*sp_ts); % Im( post_mean )
            v_re_post_ts = lambda^2 ./ (1 + lambda^2*sp_ts/sigma^2);   % Posterior variance of all arms
            v_im_post_ts = lambda^2 ./ (1 + lambda^2*sp_ts/sigma^2);
              
            % Reward generation
            X_re = mu_re + randn*sigma./sqrt(2*p_ts(ind_ts));
            X_im = mu_im + randn*sigma./sqrt(2*p_ts(ind_ts));
            X = X_re + J*X_im;

            % Update statistics
            sp_ts  = sp_ts + p_ts;
            spw_re_ts = spw_re_ts + p_ts.*X_re;
            spw_im_ts = spw_im_ts + p_ts.*X_im;
            for k = 1:K
                svhat_ts = svhat_ts + (sqrt(2*p_ts(k))*(X_re(k) - m_re_post_ts(k)))^2;
                svhat_ts = svhat_ts + (sqrt(2*p_ts(k))*(X_im(k) - m_im_post_ts(k)))^2;
            end
            vhat_ts = svhat_ts/(2*t);

            % Expected Cumulative Regret computation
            R_ts(t) = R_ts(max(t-1,1)) + max(0,maxmu^2 - p_ts'*(abs(G).^2));

            % Udapte p    
            samples_re_ts = diag(sqrt(v_re_post_ts))*randn(K,1) + m_re_post_ts;
            samples_im_ts = diag(sqrt(v_im_post_ts))*randn(K,1) + m_im_post_ts;
            samples_ts = samples_re_ts.^2 + samples_im_ts.^2;
            [~,ind_ts] = max(samples_ts);
            p_ts = zeros(K,1);
            p_ts(ind_ts) = 1;
            
        % WTS
            m_re_post_wts = lambda^2*spw_re_wts ./ (sigma^2 + lambda^2*sp_wts); % Re( post_mean )
            m_im_post_wts = lambda^2*spw_im_wts ./ (sigma^2 + lambda^2*sp_wts); % Im( post_mean )
            v_re_post_wts = lambda^2 ./ (1 + lambda^2*sp_wts/sigma^2);   % Posterior variance of all arms
            v_im_post_wts = lambda^2 ./ (1 + lambda^2*sp_wts/sigma^2);
              
            % Reward generation
            X_re = mu_re + randn*sigma./sqrt(2*p_wts);
            X_im = mu_im + randn*sigma./sqrt(2*p_wts);
            X = X_re + J*X_im;

            % Update statistics
            sp_wts  = sp_wts + p_wts;
            spw_re_wts = spw_re_wts + p_wts.*X_re;
            spw_im_wts = spw_im_wts + p_wts.*X_im;
            for k = 1:K
                svhat_wts = svhat_wts + (sqrt(2*p_wts(k))*(X_re(k) - m_re_post_wts(k)))^2;
                svhat_wts = svhat_wts + (sqrt(2*p_wts(k))*(X_im(k) - m_im_post_wts(k)))^2;
            end
            vhat_wts = svhat_wts/(2*t);

            % Expected Cumulative Regret computation
            R_wts(t) = R_wts(max(t-1,1)) + max(0,maxmu^2 - p_wts'*(abs(G).^2));

            % Udapte p    
            samples_re_wts = diag(sqrt(v_re_post_wts))*randn(K,M) + m_re_post*ones(1,M);
            samples_im_wts = diag(sqrt(v_im_post_wts))*randn(K,M) + m_im_post_wts*ones(1,M);
            samples_wts = samples_re_wts.^2 + samples_im_wts.^2;
            max_arm = zeros(K,1);
            for j = 1:M
            [~, indmax] = max(samples(:,j));
            max_arm(indmax) = max_arm(indmax) + 1;
            end
            p_wts = max_arm/M + eps;
            p_wts = p_wts/sum(p_wts);            
            

            %   Comment this to get the result faster.
    %         rplot2(K,Gplot, p, index_maxmu, t);
    end
    
    % Regret accumulation
    sR_ucbv = sR_ucbv + R_ucbv; 
    sR_ts   = sR_ts   + R_ts;
end
toc

%% SAVE
save('results.mat');

R_ucbv = sR_ucbv/Nexp;
R_ts = sR_ts/Nexp;
figure
plot(R_ucbv);
hold on
plot(R_ts);
legend('UCB-V', 'TS');


